{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXyJGSpjxix4"
      },
      "source": [
        "# modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1io1sHRusVLV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcAx_0EnIWfF",
        "outputId": "e42f0c4e-fda6-43e5-8750-afeafe07caf4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\PCPRODZ\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\PCPRODZ\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\PCPRODZ\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 321,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {},
      "outputs": [],
      "source": [
        "def submit(predictions, filename):\n",
        "    sub = {\n",
        "        'ID': [],\n",
        "        'Label': []\n",
        "    }\n",
        "    for i, p in enumerate(predictions):\n",
        "        sub['ID'].append(i)\n",
        "        sub['Label'].append('Y' if p==1 else 'N')   \n",
        "\n",
        "    df = pd.DataFrame(sub)\n",
        "    df.to_csv(f'./submission/{filename}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reZt-wgOxmJP"
      },
      "source": [
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rXxEStMPxnKB"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('./data/training_data.csv')\n",
        "df_test = pd.read_csv('./data/testing_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train['Label'].replace({'Y': 1, 'N': 0}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me5NgB50z2vd"
      },
      "source": [
        "## explore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "rvVOQB14ztIX",
        "outputId": "600a4a29-5dd3-434a-f4c9-5a32495f6e5e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Date</th>\n",
              "      <th>review ID</th>\n",
              "      <th>reviewer ID</th>\n",
              "      <th>product ID</th>\n",
              "      <th>rating_Helpful</th>\n",
              "      <th>rating_Thanks</th>\n",
              "      <th>rating_LoveThis</th>\n",
              "      <th>rating_OhNo</th>\n",
              "      <th>reviews</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5/17/2009</td>\n",
              "      <td>0dFa6egshOwhusL8aSMw-Q</td>\n",
              "      <td>8GC6cFcby0stKarnzL9i2w</td>\n",
              "      <td>dKcO9OQ44RPRlkWe-vToFA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Just got back from Shaw's. Great oysters. They...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id       Date               review ID             reviewer ID  \\\n",
              "0   0  5/17/2009  0dFa6egshOwhusL8aSMw-Q  8GC6cFcby0stKarnzL9i2w   \n",
              "\n",
              "               product ID  rating_Helpful  rating_Thanks  rating_LoveThis  \\\n",
              "0  dKcO9OQ44RPRlkWe-vToFA               0              0                0   \n",
              "\n",
              "   rating_OhNo                                            reviews  Label  \n",
              "0            4  Just got back from Shaw's. Great oysters. They...      1  "
            ]
          },
          "execution_count": 337,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_5rjE2dz1zl",
        "outputId": "9f22441d-816a-47df-ef03-7bbf60fdc9cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 47176 entries, 0 to 47175\n",
            "Data columns (total 11 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   id               47176 non-null  int64 \n",
            " 1   Date             47176 non-null  object\n",
            " 2   review ID        47176 non-null  object\n",
            " 3   reviewer ID      47176 non-null  object\n",
            " 4   product ID       47176 non-null  object\n",
            " 5   rating_Helpful   47176 non-null  int64 \n",
            " 6   rating_Thanks    47176 non-null  int64 \n",
            " 7   rating_LoveThis  47176 non-null  int64 \n",
            " 8   rating_OhNo      47176 non-null  int64 \n",
            " 9   reviews          47176 non-null  object\n",
            " 10  Label            47176 non-null  object\n",
            "dtypes: int64(5), object(6)\n",
            "memory usage: 4.0+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "u6dIBr0Fz-vk",
        "outputId": "bf21f086-7de3-4ab9-dd0f-4c130f19735c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>rating_Helpful</th>\n",
              "      <th>rating_Thanks</th>\n",
              "      <th>rating_LoveThis</th>\n",
              "      <th>rating_OhNo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>47176.00</td>\n",
              "      <td>47176.00</td>\n",
              "      <td>47176.00</td>\n",
              "      <td>47176.00</td>\n",
              "      <td>47176.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23587.50</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.84</td>\n",
              "      <td>3.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13618.68</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.57</td>\n",
              "      <td>1.93</td>\n",
              "      <td>1.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11793.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>23587.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35381.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>47175.00</td>\n",
              "      <td>78.00</td>\n",
              "      <td>68.00</td>\n",
              "      <td>78.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  rating_Helpful  rating_Thanks  rating_LoveThis  rating_OhNo\n",
              "count 47176.00        47176.00       47176.00         47176.00     47176.00\n",
              "mean  23587.50            0.45           0.53             0.84         3.93\n",
              "std   13618.68            1.65           1.57             1.93         1.13\n",
              "min       0.00            0.00           0.00             0.00         1.00\n",
              "25%   11793.75            0.00           0.00             0.00         3.00\n",
              "50%   23587.50            0.00           0.00             0.00         4.00\n",
              "75%   35381.25            0.00           1.00             1.00         5.00\n",
              "max   47175.00           78.00          68.00            78.00         5.00"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcwX27wK2JnT"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### general"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8617\n"
          ]
        }
      ],
      "source": [
        "train_reviewers = df_train['reviewer ID'].value_counts().index\n",
        "test_reviewers = df_test['reviewer ID'].value_counts().index\n",
        "\n",
        "not_present_in_train = 0\n",
        "for t in test_reviewers:\n",
        "    if t not in train_reviewers:\n",
        "        not_present_in_train += 1\n",
        "        \n",
        "print(not_present_in_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data = pd.concat([df_train, df_test])\n",
        "reviewer_counts = all_data['reviewer ID'].value_counts()\n",
        "\n",
        "# reviewer_counts = df_train['reviewer ID'].value_counts()\n",
        "\n",
        "df_train['reviewer ID'] = df_train['reviewer ID'].map(reviewer_counts)\n",
        "df_test['reviewer ID'] = df_test['reviewer ID'].map(reviewer_counts)\n",
        "# df_test['reviewer ID'] = df_test['reviewer ID'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "id": "3rwfbvUC2LMU"
      },
      "outputs": [],
      "source": [
        "percentage_y_per_product_train = df_train.groupby('product ID')['Label'].apply(lambda x: (x == 'Y').sum())\n",
        "\n",
        "df_train['product ID'] = df_train['product ID'].map(percentage_y_per_product_train)\n",
        "df_test['product ID'] = df_test['product ID'].map(percentage_y_per_product_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Date</th>\n",
              "      <th>review ID</th>\n",
              "      <th>reviewer ID</th>\n",
              "      <th>product ID</th>\n",
              "      <th>rating_Helpful</th>\n",
              "      <th>rating_Thanks</th>\n",
              "      <th>rating_LoveThis</th>\n",
              "      <th>rating_OhNo</th>\n",
              "      <th>reviews</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>weekday</th>\n",
              "      <th>quarter</th>\n",
              "      <th>is_weekend</th>\n",
              "      <th>weekday_sin</th>\n",
              "      <th>weekday_cos</th>\n",
              "      <th>month_sin</th>\n",
              "      <th>month_cos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2007-11-25</td>\n",
              "      <td>EpUIAOmCal3KLpwfRPwaSw</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Great pizza, good location, and a parking lot....</td>\n",
              "      <td>2007</td>\n",
              "      <td>11</td>\n",
              "      <td>25</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.78</td>\n",
              "      <td>0.62</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2009-03-16</td>\n",
              "      <td>WP8YNEOrIYkA-JD1pj4SoA</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>This is my favorite place in Chicago. The food...</td>\n",
              "      <td>2009</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2009-11-09</td>\n",
              "      <td>fIklWlw56IGRosS</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>A few friends and I were visiting our other fr...</td>\n",
              "      <td>2009</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2010-05-12</td>\n",
              "      <td>7wVIW6OChqj4Y4y7OiuLVw</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>How do I put this politely without offending m...</td>\n",
              "      <td>2010</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.97</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2012-08-26</td>\n",
              "      <td>GdMImdnQta4l3AkQILj2HA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Traveling through Chicago for business, they b...</td>\n",
              "      <td>2012</td>\n",
              "      <td>8</td>\n",
              "      <td>26</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.78</td>\n",
              "      <td>0.62</td>\n",
              "      <td>-0.87</td>\n",
              "      <td>-0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20214</th>\n",
              "      <td>20214</td>\n",
              "      <td>2011-11-03</td>\n",
              "      <td>XjOY6cGX0oT7PI5YI8Nj7A</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>First of all, you'll love the concept! Salad w...</td>\n",
              "      <td>2011</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20215</th>\n",
              "      <td>20215</td>\n",
              "      <td>2009-06-12</td>\n",
              "      <td>72dCIymfps2-2Tqylc</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>I finally went to try Tank after seeing all th...</td>\n",
              "      <td>2009</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.43</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20216</th>\n",
              "      <td>20216</td>\n",
              "      <td>2009-12-07</td>\n",
              "      <td>liHyGWl-RjnWuIqYIGOocw</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>I would have to say that we went to Simply It ...</td>\n",
              "      <td>2009</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20217</th>\n",
              "      <td>20217</td>\n",
              "      <td>2009-08-12</td>\n",
              "      <td>yF3JrC073ch0mSdrbJOz0g</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>A little pricey but always delicious. If I liv...</td>\n",
              "      <td>2009</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.97</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.87</td>\n",
              "      <td>-0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20218</th>\n",
              "      <td>20218</td>\n",
              "      <td>2010-04-09</td>\n",
              "      <td>-IdtfP992rP73kZIPCn22A</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>It's a cool little place with a catchy name, b...</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.43</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>0.87</td>\n",
              "      <td>-0.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20219 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id       Date               review ID  reviewer ID  product ID  \\\n",
              "0          0 2007-11-25  EpUIAOmCal3KLpwfRPwaSw            5           0   \n",
              "1          1 2009-03-16  WP8YNEOrIYkA-JD1pj4SoA            5           0   \n",
              "2          2 2009-11-09         fIklWlw56IGRosS            2           0   \n",
              "3          3 2010-05-12  7wVIW6OChqj4Y4y7OiuLVw           12           0   \n",
              "4          4 2012-08-26  GdMImdnQta4l3AkQILj2HA            1           0   \n",
              "...      ...        ...                     ...          ...         ...   \n",
              "20214  20214 2011-11-03  XjOY6cGX0oT7PI5YI8Nj7A            2           0   \n",
              "20215  20215 2009-06-12      72dCIymfps2-2Tqylc            8           0   \n",
              "20216  20216 2009-12-07  liHyGWl-RjnWuIqYIGOocw            2           0   \n",
              "20217  20217 2009-08-12  yF3JrC073ch0mSdrbJOz0g            1           0   \n",
              "20218  20218 2010-04-09  -IdtfP992rP73kZIPCn22A            4           0   \n",
              "\n",
              "       rating_Helpful  rating_Thanks  rating_LoveThis  rating_OhNo  \\\n",
              "0                   0              0                0            4   \n",
              "1                   0              0                0            5   \n",
              "2                   0              0                0            4   \n",
              "3                   1              0                1            3   \n",
              "4                   0              0                0            3   \n",
              "...               ...            ...              ...          ...   \n",
              "20214               0              0                0            4   \n",
              "20215               0              1                1            2   \n",
              "20216               0              1                0            3   \n",
              "20217               0              0                0            4   \n",
              "20218               1              0                1            2   \n",
              "\n",
              "                                                 reviews  year  month  day  \\\n",
              "0      Great pizza, good location, and a parking lot....  2007     11   25   \n",
              "1      This is my favorite place in Chicago. The food...  2009      3   16   \n",
              "2      A few friends and I were visiting our other fr...  2009     11    9   \n",
              "3      How do I put this politely without offending m...  2010      5   12   \n",
              "4      Traveling through Chicago for business, they b...  2012      8   26   \n",
              "...                                                  ...   ...    ...  ...   \n",
              "20214  First of all, you'll love the concept! Salad w...  2011     11    3   \n",
              "20215  I finally went to try Tank after seeing all th...  2009      6   12   \n",
              "20216  I would have to say that we went to Simply It ...  2009     12    7   \n",
              "20217  A little pricey but always delicious. If I liv...  2009      8   12   \n",
              "20218  It's a cool little place with a catchy name, b...  2010      4    9   \n",
              "\n",
              "       weekday  quarter  is_weekend  weekday_sin  weekday_cos  month_sin  \\\n",
              "0            6        4           1        -0.78         0.62      -0.50   \n",
              "1            0        1           0         0.00         1.00       1.00   \n",
              "2            0        4           0         0.00         1.00      -0.50   \n",
              "3            2        2           0         0.97        -0.22       0.50   \n",
              "4            6        3           1        -0.78         0.62      -0.87   \n",
              "...        ...      ...         ...          ...          ...        ...   \n",
              "20214        3        4           0         0.43        -0.90      -0.50   \n",
              "20215        4        2           0        -0.43        -0.90       0.00   \n",
              "20216        0        4           0         0.00         1.00      -0.00   \n",
              "20217        2        3           0         0.97        -0.22      -0.87   \n",
              "20218        4        2           0        -0.43        -0.90       0.87   \n",
              "\n",
              "       month_cos  \n",
              "0           0.87  \n",
              "1           0.00  \n",
              "2           0.87  \n",
              "3          -0.87  \n",
              "4          -0.50  \n",
              "...          ...  \n",
              "20214       0.87  \n",
              "20215      -1.00  \n",
              "20216       1.00  \n",
              "20217      -0.50  \n",
              "20218      -0.50  \n",
              "\n",
              "[20219 rows x 20 columns]"
            ]
          },
          "execution_count": 342,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['Date'] = pd.to_datetime(df_train['Date'])\n",
        "df_test['Date'] = pd.to_datetime(df_test['Date'])\n",
        "\n",
        "def generate_date_features(df, date_column='Date'):\n",
        "\n",
        "    df['year'] = df[date_column].dt.year\n",
        "    df['month'] = df[date_column].dt.month\n",
        "    df['day'] = df[date_column].dt.day\n",
        "    df['weekday'] = df[date_column].dt.weekday  # Monday is 0 and Sunday is 6\n",
        "    df['quarter'] = df[date_column].dt.quarter\n",
        "    df['is_weekend'] = (df[date_column].dt.weekday // 5).astype(int)  # 1 if weekend, 0 if not\n",
        "\n",
        "    # Cyclical features for circular patterns (e.g., day of week, month)\n",
        "    df['weekday_sin'] = df[date_column].dt.dayofweek.apply(lambda x: np.sin(2 * np.pi * x / 7))\n",
        "    df['weekday_cos'] = df[date_column].dt.dayofweek.apply(lambda x: np.cos(2 * np.pi * x / 7))\n",
        "    df['month_sin'] = df[date_column].dt.month.apply(lambda x: np.sin(2 * np.pi * x / 12))\n",
        "    df['month_cos'] = df[date_column].dt.month.apply(lambda x: np.cos(2 * np.pi * x / 12))\n",
        "\n",
        "    return df\n",
        "\n",
        "generate_date_features(df_train)\n",
        "generate_date_features(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_day_spam = df_train.groupby('day')['Label'].mean()\n",
        "df_train['mean_daily_spam'] = df_train['day'].map(mean_day_spam)\n",
        "df_test['mean_daily_spam'] = df_test['day'].map(mean_day_spam)\n",
        "\n",
        "mean_month_spam = df_train.groupby('month')['Label'].mean()\n",
        "df_train['mean_monthly_spam'] = df_train['month'].map(mean_month_spam)\n",
        "df_test['mean_monthly_spam'] = df_test['month'].map(mean_month_spam)\n",
        "\n",
        "mean_year_spam = df_train.groupby('year')['Label'].mean()\n",
        "df_train['mean_yearly_spam'] = df_train['year'].map(mean_year_spam)\n",
        "df_test['mean_yearly_spam'] = df_test['year'].map(mean_year_spam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [],
      "source": [
        "def most_repeated_words(text_series, top_n=10):\n",
        "    all_text = ' '.join(text_series)\n",
        "    words = word_tokenize(all_text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    word_counts = Counter(words)\n",
        "    most_common_words = word_counts.most_common(top_n)\n",
        "    return most_common_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_text_features(review):\n",
        "    # Basic features\n",
        "    word_count = len(review.split())\n",
        "    char_count = len(review)\n",
        "    avg_word_length = sum(len(word) for word in review.split()) / word_count\n",
        "\n",
        "    # Case-related features\n",
        "    uppercase_count = sum(1 for char in review if char.isupper())\n",
        "    lowercase_count = sum(1 for char in review if char.islower())\n",
        "    uppercase_lowercase_ratio = uppercase_count / (lowercase_count + 1)  # Adding 1 to avoid division by zero\n",
        "\n",
        "    # Punctuation-related features\n",
        "    punctuation_count = sum(1 for char in review if char in '.,;:!?')\n",
        "\n",
        "    # Word-related features\n",
        "    capitalized_word_count = sum(1 for word in review.split() if word.isupper())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stopword_count = sum(1 for word in review.split() if word.lower() in stop_words)\n",
        "    unique_word_count = len(set(review.split()))\n",
        "    repetition_ratio = (word_count - unique_word_count) / (word_count + 1)  # Adding 1 to avoid division by zero\n",
        "\n",
        "    # Sentiment-related features\n",
        "    sentiment = TextBlob(review).sentiment.polarity\n",
        "    subjectivity = TextBlob(review).sentiment.subjectivity\n",
        "\n",
        "    # Miscellaneous features\n",
        "    exclamation_mark_count = review.count('!')\n",
        "    question_mark_count = review.count('?')\n",
        "    numeric_count = sum(1 for char in review if char.isnumeric())\n",
        "    url_count = len(re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', review))\n",
        "    \n",
        "    features = {\n",
        "        'word_count': word_count,\n",
        "        'char_count': char_count,\n",
        "        'avg_word_length': avg_word_length,\n",
        "        'uppercase_lowercase_ratio': uppercase_lowercase_ratio,\n",
        "        'punctuation_count': punctuation_count,\n",
        "        'capitalized_word_count': capitalized_word_count,\n",
        "        'stopword_count': stopword_count,\n",
        "        'unique_word_count': unique_word_count,\n",
        "        'repetition_ratio': repetition_ratio,\n",
        "        'sentiment': sentiment,\n",
        "        'subjectivity': subjectivity,\n",
        "        'exclamation_mark_count': exclamation_mark_count,\n",
        "        'question_mark_count': question_mark_count,\n",
        "        'numeric_count': numeric_count,\n",
        "        'url_count': url_count,\n",
        "    }\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train['text_features'] = df_train['reviews'].apply(calculate_text_features)\n",
        "df_train = pd.concat([df_train, pd.DataFrame(df_train['text_features'].to_list())], axis=1)\n",
        "df_train = df_train.drop('text_features', axis=1)\n",
        "\n",
        "df_test['text_features'] = df_test['reviews'].apply(calculate_text_features)\n",
        "df_test = pd.concat([df_test, pd.DataFrame(df_test['text_features'].to_list())], axis=1)\n",
        "df_test = df_test.drop('text_features', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl9ERXk-2BQz"
      },
      "source": [
        "# X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {
        "id": "RrdbcsMr2FBe"
      },
      "outputs": [],
      "source": [
        "text_features = [\n",
        "    'word_count',\n",
        "    'char_count',\n",
        "    'avg_word_length',\n",
        "    'uppercase_lowercase_ratio',\n",
        "    'punctuation_count',\n",
        "    'capitalized_word_count',\n",
        "    'stopword_count',\n",
        "    'unique_word_count',\n",
        "    'repetition_ratio',\n",
        "    'sentiment',\n",
        "    'subjectivity',\n",
        "    'exclamation_mark_count',\n",
        "    'question_mark_count',\n",
        "    'numeric_count',\n",
        "    'url_count',\n",
        "]\n",
        "\n",
        "# time_features = [\n",
        "#     # 'year', 'month', 'day', 'weekday', 'quarter', 'is_weekend', 'weekday_sin', 'weekday_cos', 'month_sin', 'month_cos',\n",
        "#     'mean_daily_spam', 'mean_monthly_spam', 'mean_yearly_spam'             \n",
        "# ]\n",
        "\n",
        "features = ['product ID', 'reviewer ID', 'rating_Helpful', 'rating_Thanks', 'rating_LoveThis', 'rating_OhNo']\n",
        "# features = ['reviewer ID', 'rating_Helpful', 'rating_Thanks', 'rating_LoveThis', 'rating_OhNo']\n",
        "            \n",
        "# X = df_train[features + time_features + text_features]\n",
        "X = df_train[features + text_features]\n",
        "# X_test = df_test[features + time_features + text_features]\n",
        "X_test = df_test[features + text_features]\n",
        "\n",
        "y = df_train['Label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### mutual info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Feature  Mutual Information\n",
            "2  rating_LoveThis                0.03\n",
            "3      rating_OhNo                0.02\n",
            "0   rating_Helpful                0.02\n",
            "1    rating_Thanks                0.01\n"
          ]
        }
      ],
      "source": [
        "mutual_info = mutual_info_classif(X, y)\n",
        "\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Mutual Information': mutual_info})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Mutual Information', ascending=False)\n",
        "\n",
        "print(feature_importance_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['rating_LoveThis', 'reviewer ID', 'rating_Thanks',\n",
              "       'rating_Helpful', 'unique_word_count', 'rating_OhNo', 'char_count',\n",
              "       'sentiment', 'punctuation_count'], dtype=object)"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_features = feature_importance_df[feature_importance_df['Mutual Information'] > 0.01]['Feature'].values\n",
        "selected_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = X[selected_features]\n",
        "X_test = X_test[selected_features]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 356,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Importances:\n",
            "product ID: 0.0000\n",
            "reviewer ID: 0.0882\n",
            "rating_Helpful: 0.0186\n",
            "rating_Thanks: 0.0248\n",
            "rating_LoveThis: 0.0660\n",
            "rating_OhNo: 0.0412\n",
            "word_count: 0.0568\n",
            "char_count: 0.0707\n",
            "avg_word_length: 0.0776\n",
            "uppercase_lowercase_ratio: 0.0752\n",
            "punctuation_count: 0.0504\n",
            "capitalized_word_count: 0.0338\n",
            "stopword_count: 0.0556\n",
            "unique_word_count: 0.0577\n",
            "repetition_ratio: 0.0655\n",
            "sentiment: 0.0790\n",
            "subjectivity: 0.0748\n",
            "exclamation_mark_count: 0.0291\n",
            "question_mark_count: 0.0094\n",
            "numeric_count: 0.0247\n",
            "url_count: 0.0009\n"
          ]
        }
      ],
      "source": [
        "random_forest_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "random_forest_model.fit(X, y)\n",
        "\n",
        "feature_importances = random_forest_model.feature_importances_\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "for feature, importance in zip(X.columns, feature_importances):\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = RobustScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca = PCA(n_components=0.95)\n",
        "\n",
        "X = pca.fit_transform(X)\n",
        "X_test = pca.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kbest features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Feature Names: Index(['reviewer ID', 'rating_Helpful', 'rating_Thanks', 'rating_LoveThis',\n",
            "       'word_count', 'char_count', 'punctuation_count', 'stopword_count',\n",
            "       'unique_word_count', 'repetition_ratio'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "selector = SelectKBest(score_func=f_classif, k=2)\n",
        "X_pd = pd.DataFrame(X)\n",
        "X = selector.fit_transform(X_pd, y)\n",
        "\n",
        "selected_feature_indices = selector.get_support(indices=True)\n",
        "selected_feature_names = X_pd.columns[selected_feature_indices]\n",
        "\n",
        "print(\"Selected Feature Names:\", selected_feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RFE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "rfe = RFE(model, n_features_to_select=10)\n",
        "X_selected = rfe.fit_transform(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MTgW7jN30hK"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29/29 [04:40<00:00,  9.66s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Model\n",
              "RidgeClassifier              0.87\n",
              "RidgeClassifierCV            0.87\n",
              "LinearSVC                    0.87\n",
              "SGDClassifier                0.87\n",
              "DummyClassifier              0.87\n",
              "SVC                          0.87\n",
              "AdaBoostClassifier           0.87\n",
              "LGBMClassifier               0.87\n",
              "RandomForestClassifier       0.87\n",
              "LogisticRegression           0.87\n",
              "LinearDiscriminantAnalysis   0.87\n",
              "CalibratedClassifierCV       0.87\n",
              "ExtraTreesClassifier         0.87\n",
              "XGBClassifier                0.86\n",
              "BaggingClassifier            0.86\n",
              "KNeighborsClassifier         0.85\n",
              "Name: Accuracy, dtype: float64"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf = LazyClassifier(verbose=0, ignore_warnings=True)\n",
        "\n",
        "# models, predictions = clf.fit(X, y)\n",
        "models, predictions = clf.fit(X_train, X_val, y_train, y_val)\n",
        "\n",
        "accuracy = models.Accuracy\n",
        "best_models = accuracy[accuracy > 0.85]\n",
        "best_models.sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Individual Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores:\n",
            "Fold 1: 0.8764\n",
            "Fold 2: 0.8789\n",
            "Fold 3: 0.8751\n",
            "Fold 4: 0.8746\n",
            "Fold 5: 0.8733\n",
            "Mean Accuracy: 0.8757\n"
          ]
        }
      ],
      "source": [
        "xgb_model = XGBClassifier()\n",
        "\n",
        "scores = cross_val_score(xgb_model, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"Cross-Validation Scores:\")\n",
        "for fold, score in enumerate(scores, 1):\n",
        "    print(f\"Fold {fold}: {score:.4f}\")\n",
        "\n",
        "mean_accuracy = scores.mean()\n",
        "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters:  {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
            "Val Accuracy: 87.5689%\n"
          ]
        }
      ],
      "source": [
        "xgb_model = XGBClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "val_accuracy = best_model.score(X_val, y_val)\n",
        "print(\"Val Accuracy: {:.4f}%\".format(val_accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    19774\n",
              "1      445\n",
              "dtype: int64"
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series(predictions).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold: 0.67\n",
            "Predictions mean: 0.021761709283347346\n",
            "Threshold: 0.68\n",
            "Predictions mean: 0.021761709283347346\n",
            "Threshold: 0.69\n",
            "Predictions mean: 0.0\n",
            "Threshold: 0.7\n",
            "Predictions mean: 0.0\n"
          ]
        }
      ],
      "source": [
        "thresholds = [0.67, 0.68, 0.69, 0.7]\n",
        "\n",
        "for threshold in thresholds:\n",
        "    probas = best_model.predict_proba(X_test)[:, 1]  # Assuming you want probabilities for the positive class\n",
        "    predictions = [1 if p > threshold else 0 for p in probas]\n",
        "    \n",
        "    print(\"Threshold:\", threshold)\n",
        "    print(\"Predictions mean:\", sum(predictions) / len(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = [1 if p > 0.38 else 0 for p in best_model.predict_proba(X_test)[:, 1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [],
      "source": [
        "submit(predictions, 'xgb_0.38')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters:  {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100}\n",
            "Best Accuracy: 86.77%\n",
            "Val Accuracy: 86.77%\n"
          ]
        }
      ],
      "source": [
        "lgb_model = lgb.LGBMClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [None, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best Accuracy: {:.2f}%\".format(grid_search.best_score_ * 100))\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "val_accuracy = best_model.score(X, y)\n",
        "print(\"Val Accuracy: {:.2f}%\".format(val_accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters:  {'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Best Accuracy: 87.57%\n",
            "Val Accuracy: 87.57%\n"
          ]
        }
      ],
      "source": [
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10],\n",
        "    'min_samples_split': [5, 10],\n",
        "    'min_samples_leaf': [5, 10],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best Accuracy: {:.2f}%\".format(grid_search.best_score_ * 100))\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "val_accuracy = best_model.score(X, y)\n",
        "print(\"Val Accuracy: {:.2f}%\".format(val_accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters:  {'learning_rate': 0.05, 'n_estimators': 100}\n",
            "Best Accuracy: 87.55%\n",
            "Val Accuracy: 87.55%\n"
          ]
        }
      ],
      "source": [
        "ada_model = AdaBoostClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.05, 0.1]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=ada_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best Accuracy: {:.2f}%\".format(grid_search.best_score_ * 100))\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "val_accuracy = best_model.score(X, y)\n",
        "print(\"Val Accuracy: {:.2f}%\".format(val_accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0   0.87\n",
              "1   0.13\n",
              "Name: Label, dtype: float64"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.value_counts() / y.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "lgbm_classifier = LGBMClassifier(learning_rate=0.05, max_depth= 5, n_estimators= 200, random_state=42)\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200, random_state=42)\n",
        "ada_classifier = AdaBoostClassifier(learning_rate=0.1, n_estimators=200, random_state=42)\n",
        "xgb_classifier = XGBClassifier(random_state=42)\n",
        "cat_classifier = CatBoostClassifier(random_state=42, verbose=0)\n",
        "svc_classifier = SVC(probability=True, random_state=42)\n",
        "logreg_classifier = LogisticRegression(random_state=42)\n",
        "\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lgbm', lgbm_classifier),\n",
        "        ('rf', rf_classifier),\n",
        "        ('ada', ada_classifier),\n",
        "        # ('xgb', xgb_classifier),\n",
        "        # ('cat', cat_classifier),\n",
        "        # ('svc', svc_classifier),\n",
        "        # ('logreg', logreg_classifier)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross Validation Accuracies:  [0.87749046 0.8808691  0.87673556 0.87705352 0.87525172]\n",
            "Cross Validation Accuracy: 87.75%\n"
          ]
        }
      ],
      "source": [
        "cross_val_results = cross_val_score(voting_classifier, X, y, cv=5, scoring='accuracy')\n",
        "print(\"Cross Validation Accuracies: \", cross_val_results)\n",
        "print(\"Cross Validation Accuracy: {:.2f}%\".format(cross_val_results.mean() * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Accuracy: 87.59%\n"
          ]
        }
      ],
      "source": [
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "predictions = voting_classifier.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, predictions)\n",
        "print(\"Val Accuracy: {:.2f}%\".format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lgbm&#x27;,\n",
              "                              LGBMClassifier(learning_rate=0.05, max_depth=5,\n",
              "                                             n_estimators=200,\n",
              "                                             random_state=42)),\n",
              "                             (&#x27;rf&#x27;,\n",
              "                              RandomForestClassifier(min_samples_leaf=5,\n",
              "                                                     min_samples_split=5,\n",
              "                                                     n_estimators=200,\n",
              "                                                     random_state=42)),\n",
              "                             (&#x27;ada&#x27;,\n",
              "                              AdaBoostClassifier(learning_rate=0.1,\n",
              "                                                 n_estimators=200,\n",
              "                                                 random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lgbm&#x27;,\n",
              "                              LGBMClassifier(learning_rate=0.05, max_depth=5,\n",
              "                                             n_estimators=200,\n",
              "                                             random_state=42)),\n",
              "                             (&#x27;rf&#x27;,\n",
              "                              RandomForestClassifier(min_samples_leaf=5,\n",
              "                                                     min_samples_split=5,\n",
              "                                                     n_estimators=200,\n",
              "                                                     random_state=42)),\n",
              "                             (&#x27;ada&#x27;,\n",
              "                              AdaBoostClassifier(learning_rate=0.1,\n",
              "                                                 n_estimators=200,\n",
              "                                                 random_state=42))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
              "               random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_leaf=5, min_samples_split=5,\n",
              "                       n_estimators=200, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ada</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=200, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "VotingClassifier(estimators=[('lgbm',\n",
              "                              LGBMClassifier(learning_rate=0.05, max_depth=5,\n",
              "                                             n_estimators=200,\n",
              "                                             random_state=42)),\n",
              "                             ('rf',\n",
              "                              RandomForestClassifier(min_samples_leaf=5,\n",
              "                                                     min_samples_split=5,\n",
              "                                                     n_estimators=200,\n",
              "                                                     random_state=42)),\n",
              "                             ('ada',\n",
              "                              AdaBoostClassifier(learning_rate=0.1,\n",
              "                                                 n_estimators=200,\n",
              "                                                 random_state=42))])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "voting_classifier.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = voting_classifier.predict(X_test)\n",
        "\n",
        "sub = {\n",
        "    'ID': [],\n",
        "    'Label': []\n",
        "}\n",
        "\n",
        "for i, p in enumerate(predictions):\n",
        "  sub['ID'].append(i)\n",
        "  sub['Label'].append('Y' if p==1 else 'N')\n",
        "\n",
        "df = pd.DataFrame(sub)\n",
        "df.to_csv('./submission/voting.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stacking Model Accuracy: 0.876\n"
          ]
        }
      ],
      "source": [
        "lgbm_classifier = LGBMClassifier(learning_rate=0.05, max_depth=5, n_estimators=200, random_state=42)\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200, random_state=42)\n",
        "ada_classifier = AdaBoostClassifier(learning_rate=0.1, n_estimators=200, random_state=42)\n",
        "\n",
        "meta_classifier = LogisticRegression(random_state=42)\n",
        "\n",
        "stacking_classifier = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('lgbm', lgbm_classifier),\n",
        "        ('rf', rf_classifier),\n",
        "        ('ada', ada_classifier)\n",
        "    ],\n",
        "    final_estimator=meta_classifier,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "stacking_classifier.fit(X, y)\n",
        "\n",
        "stacking_predictions = stacking_classifier.predict(X)\n",
        "accuracy = accuracy_score(y, stacking_predictions)\n",
        "print(f\"Stacking Model Accuracy: {accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = stacking_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Dense(128, input_shape=(X.shape[1],), activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=1e-2), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.7661 - val_loss: 0.4956 - val_accuracy: 0.9243\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4152 - accuracy: 0.7814 - val_loss: 0.6783 - val_accuracy: 0.7750\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4048 - accuracy: 0.7906 - val_loss: 0.4660 - val_accuracy: 0.8911\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3961 - accuracy: 0.7899 - val_loss: 0.5258 - val_accuracy: 0.8811\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3948 - accuracy: 0.7959 - val_loss: 0.5347 - val_accuracy: 0.8419\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3881 - accuracy: 0.7994 - val_loss: 0.6568 - val_accuracy: 0.8387\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3861 - accuracy: 0.8016 - val_loss: 0.4764 - val_accuracy: 0.8635\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3819 - accuracy: 0.8024 - val_loss: 0.4996 - val_accuracy: 0.8295\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3770 - accuracy: 0.8079 - val_loss: 0.4708 - val_accuracy: 0.8763\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3732 - accuracy: 0.8092 - val_loss: 0.4722 - val_accuracy: 0.9035\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1ec711b2940>"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKuPhoShIWfI"
      },
      "source": [
        "## LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LUUVl8NAIWfI"
      },
      "outputs": [],
      "source": [
        "X_text = df_train[['reviews']]\n",
        "X_text_test = df_test[['reviews']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_text = df_train['Label']\n",
        "y_text.replace({'Y': 1, 'N':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((47176, 11), (47176,))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape, y_text.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVM1RtiaIWfI"
      },
      "source": [
        "### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1TEBX3WIWfI",
        "outputId": "5d0352a9-742b-4e7a-8edd-af82e0c7867a"
      },
      "outputs": [],
      "source": [
        "X_text['reviews'] = X_text['reviews'].str.lower()\n",
        "X_text_test['reviews'] = X_text_test['reviews'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwZYoqonIWfI",
        "outputId": "9141a7a0-94ae-44c6-fa54-35ca90e52912"
      },
      "outputs": [],
      "source": [
        "X_text['reviews'] = X_text['reviews'].str.replace('[^\\w\\s]', '')\n",
        "X_text_test['reviews'] = X_text_test['reviews'].str.replace('[^\\w\\s]', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwwwk0KDIWfI",
        "outputId": "e45c2de0-ea99-4380-95e7-676a44306bcf"
      },
      "outputs": [],
      "source": [
        "X_text['reviews'] = X_text['reviews'].apply(word_tokenize)\n",
        "X_text_test['reviews'] = X_text_test['reviews'].apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbyqX70xIWfJ",
        "outputId": "065874da-b224-48c1-c890-04d28be81798"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "X_text['reviews'] = X_text['reviews'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
        "X_text_test['reviews'] = X_text_test['reviews'].apply(lambda tokens: [word for word in tokens if word not in stop_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9r9onmXIWfJ"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "X_text['reviews'] = X_text['reviews'].apply(lambda tokens: [stemmer.stem(word) for word in tokens])\n",
        "X_text_test['reviews'] = X_text_test['reviews'].apply(lambda tokens: [stemmer.stem(word) for word in tokens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKoUw6yXIWfJ",
        "outputId": "59ae3158-475f-43e3-c438-50de6d21d65a"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "X_text['reviews'] = X_text['reviews'].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])\n",
        "X_text_test['reviews'] = X_text_test['reviews'].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH_PVCWFIWfJ",
        "outputId": "f9628fba-2eff-422a-8fb5-0c6cd098a546"
      },
      "outputs": [],
      "source": [
        "X_text['reviews'] = X_text['reviews'].apply(lambda tokens: ' '.join(tokens))\n",
        "X_text_test['reviews'] = X_text_test['reviews'].apply(lambda tokens: ' '.join(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = pd.concat([X_text, y_text], axis = 1)\n",
        "df_clean.to_csv('clean.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_text_test.to_csv('clean_test.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHblze2tIWfJ"
      },
      "source": [
        "### training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sjqYm-3IWfJ",
        "outputId": "743f3ae8-99f6-4ac6-9d56-8bf71d1f0540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Unique Words: 101201\n"
          ]
        }
      ],
      "source": [
        "all_text = pd.concat([X_text['reviews'], X_text_test['reviews']])\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_text)\n",
        "\n",
        "num_unique_words = len(tokenizer.word_index)\n",
        "print(\"Number of Unique Words:\", num_unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "sfJyLLj5IWfK"
      },
      "outputs": [],
      "source": [
        "max_words = num_unique_words\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(all_text)\n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_text['reviews'])\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_text_test['reviews'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "WTdBE_g3IWfK"
      },
      "outputs": [],
      "source": [
        "max_len = max(len(seq) for seq in X_train_sequences)\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "KzZNkeUUIWfK"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 64\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len),\n",
        "    Bidirectional(LSTM(32, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "L-T7_tpJIWfK"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=5e-2), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYHBpXpDIWfL",
        "outputId": "562f93a6-d47c-4bd4-8f69-16d9b39e085c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "369/369 [==============================] - 81s 202ms/step - loss: 0.3958 - accuracy: 0.8634\n",
            "Epoch 2/2\n",
            "369/369 [==============================] - 51s 138ms/step - loss: 0.3816 - accuracy: 0.8676\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f9f84356260>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_padded, y_text, epochs=2, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO0L9GRiXMAS",
        "outputId": "67c1d0d6-18d3-4573-f0a7-03354f7cf2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "632/632 [==============================] - 18s 27ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(X_test_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "dbUqFx40XSlR"
      },
      "outputs": [],
      "source": [
        "predictions = ['Y' if x[0]>0.5 else 'N' for x in preds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlWph1FgXW8f",
        "outputId": "80b1ce52-cfc2-49b1-9bcd-e9e43b9f1b49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "N    20219\n",
              "dtype: int64"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series(predictions).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Bl4n9YQuXnpn"
      },
      "outputs": [],
      "source": [
        "sub = {\n",
        "    'ID': [],\n",
        "    'Label': []\n",
        "}\n",
        "\n",
        "for i, p in enumerate(predictions):\n",
        "  sub['ID'].append(i)\n",
        "  sub['Label'].append(p)\n",
        "\n",
        "df = pd.DataFrame(sub)\n",
        "df.to_csv('./lstm.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QXyJGSpjxix4",
        "reZt-wgOxmJP",
        "Yl9ERXk-2BQz",
        "_MTgW7jN30hK",
        "-z7XtyZ6IWfH",
        "VKuPhoShIWfI",
        "jHblze2tIWfJ"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
